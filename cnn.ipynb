{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KtOi2DDWNfcs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from config import Config, Device\n",
        "from datasets import MRIDataset\n",
        "from models import CNN\n",
        "from train import Trainer\n",
        "from test_file import Tester"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mps\n"
          ]
        }
      ],
      "source": [
        "device = Device.device\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_path = os.path.join(os.getcwd(), \"data\")\n",
        "labels_path = \"train.csv\"\n",
        "\n",
        "batch_size = Config.batch_size\n",
        "num_epochs = Config.num_epochs\n",
        "learning_rate = Config.learning_rate\n",
        "image_size = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = MRIDataset(\n",
        "    data_path, labels_path, split=\"train\", transform=train_transforms, max_slices=20)\n",
        "    \n",
        "val_dataset = MRIDataset(data_path, labels_path, split=\"val\",\n",
        "                         transform=test_transforms, max_slices=20)\n",
        "test_dataset = MRIDataset(\n",
        "    data_path, labels_path, split=\"test\", transform=test_transforms, max_slices=20)\n",
        "\n",
        "\n",
        "train_dl = DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "val_dl = DataLoader(val_dataset, batch_size)\n",
        "test_dl = DataLoader(test_dataset, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (cnn1): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (cnn2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=476288, out_features=300, bias=True)\n",
              "  (fc2): Linear(in_features=300, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = CNN().to(device=device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Weights: tensor(4.0051)\n"
          ]
        }
      ],
      "source": [
        "def compute_class_weights_from_csv(csv_file_path):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(csv_file_path)\n",
        "\n",
        "    labels = df['prediction'].values\n",
        "\n",
        "    # Convert labels to integers if they are not already\n",
        "    labels = labels.astype(int)\n",
        "\n",
        "    # Compute class weights\n",
        "    unique_labels = np.unique(labels)\n",
        "    class_weights = compute_class_weight(\n",
        "        class_weight='balanced', classes=unique_labels, y=labels)\n",
        "\n",
        "    # Convert to torch tensor\n",
        "    return torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "\n",
        "# Path to your CSV file\n",
        "class_weights = compute_class_weights_from_csv(labels_path)\n",
        "\n",
        "# For binary classification, use the appropriate class weight\n",
        "# Assuming binary classification with class labels 0 and 1\n",
        "class_weights = class_weights[1]  # Adjust if necessary\n",
        "print(\"Class Weights:\", class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    The focal loss for fighting against class-imbalance\n",
        "    \"\"\"\n",
        "    def __init__(self, class_weights, device, alpha=1, gamma=2):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = 1e-8  # prevent training from Nan-loss error\n",
        "        self.device = device\n",
        "        \n",
        "        # Ensure class_weights is a tensor and moved to the correct device\n",
        "        self.class_weights = class_weights.clone().detach().to(self.device) if class_weights is not None else None\n",
        "\n",
        "    def forward(self, logits, target):\n",
        "        \"\"\"\n",
        "        logits & target should be tensors with shape [batch_size, num_classes]\n",
        "        \"\"\"\n",
        "        probs = torch.sigmoid(logits)\n",
        "        one_subtract_probs = 1.0 - probs\n",
        "        # add epsilon\n",
        "        probs_new = probs + self.epsilon\n",
        "        one_subtract_probs_new = one_subtract_probs + self.epsilon\n",
        "        # calculate focal loss\n",
        "        log_pt = target * torch.log(probs_new) + (1.0 - target) * torch.log(one_subtract_probs_new)\n",
        "        pt = torch.exp(log_pt)\n",
        "        focal_loss = -1.0 * (self.alpha * (1 - pt) ** self.gamma) * log_pt\n",
        "\n",
        "\n",
        "        if self.class_weights is not None:\n",
        "            focal_loss = focal_loss * self.class_weights\n",
        "        \n",
        "        return torch.mean(focal_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# loss and optimizer\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss().to(device)\n",
        "# criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights).to(device)\n",
        "# criterion = FocalLoss(class_weights=class_weights, device=device).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'CNN'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_name = model.__class__.__name__\n",
        "model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    train_dl=train_dl,\n",
        "    val_dl=val_dl,\n",
        "    train_dataset=train_dataset,\n",
        "    val_dataset=val_dataset,\n",
        "    device=device,\n",
        "    num_epochs=num_epochs,\n",
        "    patience=5,\n",
        "    threshold=0.5,\n",
        "    save_path=f\"saved_models/{model_name}.pth\"\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = CNN().to(device=device)\n",
        "model.load_state_dict(torch.load(f\"saved_models/{model_name}.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tester = Tester(\n",
        "    model=model,\n",
        "    test_dl=test_dl,\n",
        "    test_dataset=test_dataset,\n",
        "    device=device,\n",
        "    threshold=0.5\n",
        ")\n",
        "\n",
        "tester.test()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
