{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nthe model consists of autoenocer and classifier\\nthere are 2 loss functions for those two parts\\nsounds suitable for noisy data and not enough data, \\n\\nInput Image -> [Encoder Layers] -> Latent Space -> [Decoder Layers] -> Reconstructed Image\\n                                 |\\n                                 -> Fully Connected Classification Head -> Predicted Class\\n\\nfor both loss functions BCE is used\\nthe model use sigmoid in the last layer\\n\\ninput image size: 64 X 64\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "the model consists of autoenocer and classifier\n",
    "there are 2 loss functions for those two parts\n",
    "sounds suitable for noisy data and not enough data, \n",
    "\n",
    "Input Image -> [Encoder Layers] -> Latent Space -> [Decoder Layers] -> Reconstructed Image\n",
    "                                 |\n",
    "                                 -> Fully Connected Classification Head -> Predicted Class\n",
    "\n",
    "for both loss functions BCE is used\n",
    "the model use sigmoid in the last layer\n",
    "\n",
    "input image size: 64 X 64\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from config import Config, Device\n",
    "from datasets import BalancedMRIDataset\n",
    "from models import autoencoder\n",
    "from trainer import Trainer_AutoencoderClassification\n",
    "from tester import Tester_AutoencoderClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = Device.device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(), \"data\")\n",
    "labels_path = \"train.csv\"\n",
    "\n",
    "batch_size = Config.batch_size\n",
    "num_epochs = Config.num_epochs\n",
    "learning_rate = Config.learning_rate\n",
    "mean = Config.mean  # mean of the entire datasaet\n",
    "std = Config.std  # std of the entire dataaset\n",
    "image_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resclaed_mean = round(mean/255, 4)  # re-scale the actual mean\n",
    "rescaled_std = round(std/255, 4)  # re-scale the actual std\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[resclaed_mean], std=[rescaled_std])\n",
    "])\n",
    "\n",
    "augment_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    # transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[resclaed_mean], std=[rescaled_std])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    # transforms.Lambda(lambda img: img.astype(np.float32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.Normalize(mean=[resclaed_mean], std=[rescaled_std])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = BalancedMRIDataset(\n",
    "    data_path,\n",
    "    labels_path,\n",
    "    split='train',\n",
    "    transform=train_transforms,\n",
    "    augment_transform=augment_transforms,\n",
    "    augment=True,\n",
    "    max_slices=20\n",
    ")\n",
    "\n",
    "val_dataset = BalancedMRIDataset(\n",
    "    data_path,\n",
    "    labels_path,\n",
    "    split='val',\n",
    "    transform=test_transforms,\n",
    "    max_slices=20\n",
    ")\n",
    "\n",
    "test_dataset = BalancedMRIDataset(\n",
    "    data_path,\n",
    "    labels_path,\n",
    "    split='test',\n",
    "    transform=test_transforms,\n",
    "    max_slices=20\n",
    ")\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size=32)\n",
    "test_dl = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20, 64, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_, label_ = next(iter(train_dl))\n",
    "data_.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder.AutoencoderClassifier().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion_reconstruction = nn.BCEWithLogitsLoss()  # For reconstruction loss\n",
    "criterion_classification = nn.BCEWithLogitsLoss()   # For classification loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AutoencoderClassifier'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = model.__class__.__name__\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer_AutoencoderClassification(\n",
    "    model=model,\n",
    "    criterion=[criterion_reconstruction , criterion_classification],\n",
    "    optimizer=optimizer,\n",
    "    train_dl=train_dl,\n",
    "    val_dl=val_dl,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    device=device,\n",
    "    num_epochs=1,\n",
    "    patience=100,\n",
    "    threshold=0.5,\n",
    "    save_path=f\"saved_models/{model_name}.pth\"\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"saved_models/{model_name}_best.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: -18769.9094, Test Accuracy: 0.8754\n",
      "Precision: 0.0000, Recall: 0.0000, AUC: 0.5000, Avg Metric: 0.0000\n",
      "Confusion Matrix:\n",
      "[[548   0]\n",
      " [ 78   0]]\n"
     ]
    }
   ],
   "source": [
    "tester = Tester_AutoencoderClassification(\n",
    "    model=model,\n",
    "    criterion=[criterion_reconstruction , criterion_classification],\n",
    "    test_dl=test_dl,\n",
    "    test_dataset=test_dataset,\n",
    "    device=device,\n",
    "    threshold=0.5\n",
    ")\n",
    "\n",
    "tester.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.16.2 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "E0903 18:11:22.356342 6213545984 _internal.py:97] Error on request:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/werkzeug/serving.py\", line 363, in run_wsgi\n",
      "    execute(self.server.app)\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/werkzeug/serving.py\", line 324, in execute\n",
      "    application_iter = app(environ, start_response)\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/tensorboard/backend/application.py\", line 528, in __call__\n",
      "    return self._app(environ, start_response)\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/tensorboard/backend/application.py\", line 569, in wrapper\n",
      "    return wsgi_app(environ, start_response)\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/tensorboard/backend/security_validator.py\", line 91, in __call__\n",
      "    return self._application(environ, start_response_proxy)\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/tensorboard/backend/path_prefix.py\", line 68, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/tensorboard/backend/experiment_id.py\", line 73, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/tensorboard/backend/empty_path_redirect.py\", line 43, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/tensorboard/backend/client_feature_flags.py\", line 55, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/tensorboard/backend/auth_context_middleware.py\", line 38, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/tensorboard/backend/application.py\", line 551, in _route_request\n",
      "    return self.exact_routes[clean_path](environ, start_response)\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/werkzeug/wrappers/request.py\", line 190, in application\n",
      "    resp = f(*args[:-2] + (request,))\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/tensorboard/plugins/hparams/hparams_plugin.py\", line 121, in get_experiment_route\n",
      "    json_format.MessageToJson(\n",
      "TypeError: MessageToJson() got an unexpected keyword argument 'including_default_value_fields'\n",
      "E0903 18:11:22.441874 6196719616 _internal.py:97] Error on request:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/werkzeug/serving.py\", line 363, in run_wsgi\n",
      "    execute(self.server.app)\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/werkzeug/serving.py\", line 324, in execute\n",
      "    application_iter = app(environ, start_response)\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/tensorboard/backend/application.py\", line 528, in __call__\n",
      "    return self._app(environ, start_response)\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/tensorboard/backend/application.py\", line 569, in wrapper\n",
      "    return wsgi_app(environ, start_response)\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/tensorboard/backend/security_validator.py\", line 91, in __call__\n",
      "    return self._application(environ, start_response_proxy)\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/tensorboard/backend/path_prefix.py\", line 68, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/tensorboard/backend/experiment_id.py\", line 73, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/tensorboard/backend/empty_path_redirect.py\", line 43, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/tensorboard/backend/client_feature_flags.py\", line 55, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/tensorboard/backend/auth_context_middleware.py\", line 38, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/tensorboard/backend/application.py\", line 551, in _route_request\n",
      "    return self.exact_routes[clean_path](environ, start_response)\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/werkzeug/wrappers/request.py\", line 190, in application\n",
      "    resp = f(*args[:-2] + (request,))\n",
      "  File \"/Users/anazarnia/data_science/myenv_1/lib/python3.9/site-packages/tensorboard/plugins/hparams/hparams_plugin.py\", line 121, in get_experiment_route\n",
      "    json_format.MessageToJson(\n",
      "TypeError: MessageToJson() got an unexpected keyword argument 'including_default_value_fields'\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# !tensorboard --logdir=runs/training/{self.model.__class__.__name__}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Hyperparameters\n",
    "# num_epochs = 50\n",
    "# batch_size = 32\n",
    "# learning_rate = 0.001\n",
    "\n",
    "# # Create DataLoader (Assuming `train_images` and `train_labels` are loaded)\n",
    "# transform = transforms.Compose([transforms.ToTensor()])\n",
    "# train_dataset = BrainImageDataset(train_images, train_labels, transform=transform)\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# # Model, Loss, Optimizer\n",
    "# model = AutoencoderClassifier()\n",
    "# criterion_reconstruction = nn.BCELoss()  # For reconstruction loss\n",
    "# criterion_classification = nn.BCELoss()   # For classification loss\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# # Training Loop\n",
    "# for epoch in range(num_epochs):\n",
    "#     for images, labels in train_loader:\n",
    "#         # Flatten the images for the classifier\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         # Forward pass\n",
    "#         reconstructed, outputs = model(images)\n",
    "        \n",
    "#         # Compute losses\n",
    "#         loss_reconstruction = criterion_reconstruction(reconstructed, images)\n",
    "#         loss_classification = criterion_classification(outputs.squeeze(), labels.float())\n",
    "#         loss = loss_reconstruction + loss_classification\n",
    "        \n",
    "#         # Backward pass and optimization\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# # Saving the model\n",
    "# torch.save(model.state_dict(), \"autoencoder_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
