{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "all the model tuned\n",
    "balanced data used (BalancedMRIDataset)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fateme/Projects/iaaa-project/iaaa-venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from config import Config, Device\n",
    "from datasets import MRIDataset, BalancedMRIDataset\n",
    "from models import MriResentModel\n",
    "from trainer import Trainer\n",
    "from tester import Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = Device.device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(), \"data\")\n",
    "labels_path = \"train.csv\"\n",
    "\n",
    "batch_size = Config.batch_size\n",
    "num_epochs = Config.num_epochs\n",
    "learning_rate = Config.learning_rate\n",
    "mean = Config.mean # mean of the entire datasaet\n",
    "std = Config.std # std of the entire dataaset\n",
    "image_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resclaed_mean = round(mean/255,4) # re-scale the actual mean\n",
    "rescaled_std = round(std/255, 4) # re-scale the actual std\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[resclaed_mean], std=[rescaled_std])\n",
    "])\n",
    "\n",
    "augment_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    # transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[resclaed_mean], std=[rescaled_std])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    # transforms.Lambda(lambda img: img.astype(np.float32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize(mean=[resclaed_mean], std=[rescaled_std])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BalancedMRIDataset(\n",
    "    data_path,\n",
    "    labels_path,\n",
    "    split='train',\n",
    "    transform=train_transforms,\n",
    "    augment_transform=augment_transforms,\n",
    "    augment=True,\n",
    "    max_slices=20\n",
    ")\n",
    "\n",
    "val_dataset = BalancedMRIDataset(\n",
    "    data_path,\n",
    "    labels_path,\n",
    "    split='val',\n",
    "    transform=test_transforms,\n",
    "    max_slices=20\n",
    ")\n",
    "\n",
    "test_dataset = BalancedMRIDataset(\n",
    "    data_path,\n",
    "    labels_path,\n",
    "    split='test',\n",
    "    transform=test_transforms,\n",
    "    max_slices=20\n",
    ")\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size=32)\n",
    "test_dl = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20, 224, 224])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_, label_ = next(iter(train_dl))\n",
    "data_.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MriResentModel(1,1).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5713, 4.0051])\n",
      "Class Weights: tensor(4.0051)\n"
     ]
    }
   ],
   "source": [
    "def compute_class_weights_from_csv(csv_file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    labels = df['prediction'].values\n",
    "\n",
    "    # Convert labels to integers if they are not already\n",
    "    labels = labels.astype(int)\n",
    "\n",
    "    # Compute class weights\n",
    "    unique_labels = np.unique(labels)\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced', classes=unique_labels, y=labels)\n",
    "\n",
    "    # Convert to torch tensor\n",
    "    return torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "\n",
    "# Path to your CSV file\n",
    "class_weights = compute_class_weights_from_csv(labels_path)\n",
    "print(class_weights)\n",
    "# For binary classification, use the appropriate class weight\n",
    "# Assuming binary classification with class labels 0 and 1\n",
    "class_weights = class_weights[1]  # Adjust if necessary\n",
    "print(\"Class Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "# criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MriResentModel'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = model.__class__.__name__\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [17:57<00:00, 12.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[10960     0]\n",
      " [ 1560     0]]\n",
      "Epoch 1/4, Train Loss: 1222.8494, Train Accuracy: 0.5606\n",
      "Epoch 1/4, Val Accuracy: 17.5080, Precision: 0.0000, Recall: 0.0000, AUC: 0.5000, Avg Metric: 5.8360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [17:51<00:00, 12.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[10960     0]\n",
      " [ 1560     0]]\n",
      "Epoch 2/4, Train Loss: 1219.0895, Train Accuracy: 0.5677\n",
      "Epoch 2/4, Val Accuracy: 17.5080, Precision: 0.0000, Recall: 0.0000, AUC: 0.5000, Avg Metric: 5.8360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [18:09<00:00, 12.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[10960     0]\n",
      " [ 1560     0]]\n",
      "Epoch 3/4, Train Loss: 1222.0585, Train Accuracy: 0.5574\n",
      "Epoch 3/4, Val Accuracy: 17.5080, Precision: 0.0000, Recall: 0.0000, AUC: 0.5000, Avg Metric: 5.8360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [18:04<00:00, 12.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[10960     0]\n",
      " [ 1560     0]]\n",
      "Epoch 4/4, Train Loss: 1220.9354, Train Accuracy: 0.5500\n",
      "Epoch 4/4, Val Accuracy: 17.5080, Precision: 0.0000, Recall: 0.0000, AUC: 0.5000, Avg Metric: 5.8360\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    train_dl=train_dl,\n",
    "    val_dl=val_dl,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    device=device,\n",
    "    num_epochs=4,\n",
    "    patience=5,\n",
    "    threshold=0.5,\n",
    "    save_path=f\"saved_models/{model_name}.pth\"\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fateme/Projects/iaaa-project/iaaa-venv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/fateme/Projects/iaaa-project/iaaa-venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MriResentModel(1,1).to(device)\n",
    "model.load_state_dict(torch.load(f\"saved_models/{model_name}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7604, Precision: 0.2049, Recall: 0.3205, AUC: 0.5926, Avg Metric: 0.3727\n"
     ]
    }
   ],
   "source": [
    "tester = Tester(\n",
    "    model=model,\n",
    "    criterion = criterion,\n",
    "    test_dl=test_dl,\n",
    "    test_dataset=test_dataset,\n",
    "    device=device,\n",
    "    threshold=0  # Set the threshold for binary classification\n",
    ")\n",
    "\n",
    "# Perform testing and print metrics\n",
    "tester.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
