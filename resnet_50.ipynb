{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nchallenge: resnet input: 3 channels images, the mri images: 20 channels\\n-> 1 layer (conv2d) to transform 16 to 3 berfore resnet model\\n\\nchallenge: using pretrained resent50 model and update all parameters (aksh-ai)\\nor just fine tune last layer\\n-> update all parameters\\nchallenge: resnet-50 transform normalizing is not applicable\\nwe have gray scale 18 channel data \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "challenge: resnet input: 3 channels images, the mri images: 20 channels\n",
    "-> 1 layer (conv2d) to transform 16 to 3 berfore resnet model\n",
    "\n",
    "challenge: using pretrained resent50 model and update all parameters (aksh-ai)\n",
    "or just fine tune last layer\n",
    "-> update all parameters\n",
    "challenge: resnet-50 transform normalizing is not applicable\n",
    "we have gray scale 18 channel data \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from config import Config, Device\n",
    "from datasets import MRIDataset\n",
    "from models import MriResentModel\n",
    "from train import Trainer\n",
    "from test_file import Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = Device.device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(), \"data\")\n",
    "labels_path = \"train.csv\"\n",
    "\n",
    "batch_size = Config.batch_size\n",
    "num_epochs = Config.num_epochs\n",
    "learning_rate = Config.learning_rate\n",
    "image_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MRIDataset(\n",
    "    data_path, labels_path, split=\"train\", transform=train_transforms, max_slices=20)\n",
    "    \n",
    "val_dataset = MRIDataset(data_path, labels_path, split=\"val\",\n",
    "                         transform=test_transforms, max_slices=20)\n",
    "test_dataset = MRIDataset(\n",
    "    data_path, labels_path, split=\"test\", transform=test_transforms, max_slices=20)\n",
    "\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size)\n",
    "test_dl = DataLoader(test_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fateme/Projects/iaaa-project/iaaa-venv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/fateme/Projects/iaaa-project/iaaa-venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MriResentModel(\n",
       "  (conv): Conv2d(20, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (resnet_model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): SELU()\n",
       "      (2): Dropout(p=0.4, inplace=False)\n",
       "      (3): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (4): SELU()\n",
       "      (5): Dropout(p=0.4, inplace=False)\n",
       "      (6): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MriResentModel(20,1).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5713, 4.0051])\n",
      "Class Weights: tensor(4.0051)\n"
     ]
    }
   ],
   "source": [
    "def compute_class_weights_from_csv(csv_file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    labels = df['prediction'].values\n",
    "\n",
    "    # Convert labels to integers if they are not already\n",
    "    labels = labels.astype(int)\n",
    "\n",
    "    # Compute class weights\n",
    "    unique_labels = np.unique(labels)\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced', classes=unique_labels, y=labels)\n",
    "\n",
    "    # Convert to torch tensor\n",
    "    return torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "\n",
    "# Path to your CSV file\n",
    "class_weights = compute_class_weights_from_csv(labels_path)\n",
    "print(class_weights)\n",
    "# For binary classification, use the appropriate class weight\n",
    "# Assuming binary classification with class labels 0 and 1\n",
    "class_weights = class_weights[1]  # Adjust if necessary\n",
    "print(\"Class Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights).to(device)\n",
    "# criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MriResentModel'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = model.__class__.__name__\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:03<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 1/100, Train Loss: 108.5508, Train Accuracy: 0.1250\n",
      "Epoch 1/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5000, Avg Metric: 0.5415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:58<00:00,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 2/100, Train Loss: 125.3991, Train Accuracy: 0.1255\n",
      "Epoch 2/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5139, Avg Metric: 0.5462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:00<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 3/100, Train Loss: 75.0770, Train Accuracy: 0.1250\n",
      "Epoch 3/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5125, Avg Metric: 0.5457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:01<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 13 535]\n",
      " [  2  76]]\n",
      "Epoch 4/100, Train Loss: 57.2313, Train Accuracy: 0.1250\n",
      "Epoch 4/100, Val Accuracy: 0.1422, Precision: 0.1244, Recall: 0.9744, AUC: 0.4745, Avg Metric: 0.5244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:04<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 5/100, Train Loss: 56.1505, Train Accuracy: 0.1250\n",
      "Epoch 5/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5206, Avg Metric: 0.5484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:02<00:00,  3.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 6/100, Train Loss: 55.3161, Train Accuracy: 0.1250\n",
      "Epoch 6/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5221, Avg Metric: 0.5489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:11<00:00,  3.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 7/100, Train Loss: 53.2724, Train Accuracy: 0.1250\n",
      "Epoch 7/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5227, Avg Metric: 0.5491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:17<00:00,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 8/100, Train Loss: 53.8397, Train Accuracy: 0.1250\n",
      "Epoch 8/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5088, Avg Metric: 0.5445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:02<00:00,  3.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 9/100, Train Loss: 52.8057, Train Accuracy: 0.1250\n",
      "Epoch 9/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5139, Avg Metric: 0.5462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:04<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 10/100, Train Loss: 53.3605, Train Accuracy: 0.1250\n",
      "Epoch 10/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5312, Avg Metric: 0.5519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:03<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 11/100, Train Loss: 52.9281, Train Accuracy: 0.1250\n",
      "Epoch 11/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5386, Avg Metric: 0.5544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:03<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 12/100, Train Loss: 52.9736, Train Accuracy: 0.1250\n",
      "Epoch 12/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5203, Avg Metric: 0.5483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:03<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 13/100, Train Loss: 53.1612, Train Accuracy: 0.1250\n",
      "Epoch 13/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5329, Avg Metric: 0.5525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:03<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 14/100, Train Loss: 52.8059, Train Accuracy: 0.1250\n",
      "Epoch 14/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5269, Avg Metric: 0.5505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:02<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 15/100, Train Loss: 53.1732, Train Accuracy: 0.1250\n",
      "Epoch 15/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5334, Avg Metric: 0.5527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:03<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 16/100, Train Loss: 52.8623, Train Accuracy: 0.1250\n",
      "Epoch 16/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5269, Avg Metric: 0.5505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:02<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 17/100, Train Loss: 53.3531, Train Accuracy: 0.1250\n",
      "Epoch 17/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5288, Avg Metric: 0.5511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:00<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 18/100, Train Loss: 52.8942, Train Accuracy: 0.1250\n",
      "Epoch 18/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5104, Avg Metric: 0.5450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:02<00:00,  3.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 19/100, Train Loss: 52.6823, Train Accuracy: 0.1250\n",
      "Epoch 19/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5461, Avg Metric: 0.5569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:01<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 20/100, Train Loss: 53.0765, Train Accuracy: 0.1250\n",
      "Epoch 20/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5528, Avg Metric: 0.5591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:01<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 21/100, Train Loss: 52.8048, Train Accuracy: 0.1250\n",
      "Epoch 21/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5481, Avg Metric: 0.5576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:02<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 22/100, Train Loss: 52.5280, Train Accuracy: 0.1250\n",
      "Epoch 22/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5353, Avg Metric: 0.5533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:01<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 23/100, Train Loss: 52.3735, Train Accuracy: 0.1250\n",
      "Epoch 23/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5334, Avg Metric: 0.5527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:00<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 24/100, Train Loss: 52.7954, Train Accuracy: 0.1250\n",
      "Epoch 24/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5179, Avg Metric: 0.5475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:00<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 25/100, Train Loss: 52.6818, Train Accuracy: 0.1250\n",
      "Epoch 25/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5284, Avg Metric: 0.5510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:00<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 26/100, Train Loss: 52.7201, Train Accuracy: 0.1250\n",
      "Epoch 26/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5357, Avg Metric: 0.5534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:01<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 27/100, Train Loss: 52.7641, Train Accuracy: 0.1250\n",
      "Epoch 27/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5201, Avg Metric: 0.5482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:54<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 28/100, Train Loss: 53.0213, Train Accuracy: 0.1250\n",
      "Epoch 28/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5150, Avg Metric: 0.5465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:50<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 29/100, Train Loss: 52.7518, Train Accuracy: 0.1250\n",
      "Epoch 29/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5142, Avg Metric: 0.5463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:52<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 30/100, Train Loss: 52.4431, Train Accuracy: 0.1250\n",
      "Epoch 30/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5136, Avg Metric: 0.5461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:00<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 31/100, Train Loss: 52.6693, Train Accuracy: 0.1250\n",
      "Epoch 31/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5330, Avg Metric: 0.5525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:59<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 32/100, Train Loss: 52.8984, Train Accuracy: 0.1250\n",
      "Epoch 32/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5229, Avg Metric: 0.5492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:01<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 33/100, Train Loss: 52.4524, Train Accuracy: 0.1250\n",
      "Epoch 33/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5185, Avg Metric: 0.5477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:01<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 34/100, Train Loss: 52.6840, Train Accuracy: 0.1250\n",
      "Epoch 34/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5297, Avg Metric: 0.5514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:01<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 35/100, Train Loss: 52.5402, Train Accuracy: 0.1250\n",
      "Epoch 35/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5230, Avg Metric: 0.5492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:59<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 36/100, Train Loss: 52.8478, Train Accuracy: 0.1250\n",
      "Epoch 36/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5333, Avg Metric: 0.5526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:59<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 37/100, Train Loss: 52.7289, Train Accuracy: 0.1250\n",
      "Epoch 37/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5166, Avg Metric: 0.5471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:59<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 38/100, Train Loss: 52.4584, Train Accuracy: 0.1250\n",
      "Epoch 38/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5197, Avg Metric: 0.5481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:59<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 39/100, Train Loss: 52.6853, Train Accuracy: 0.1250\n",
      "Epoch 39/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5054, Avg Metric: 0.5433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:00<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 40/100, Train Loss: 52.1425, Train Accuracy: 0.1250\n",
      "Epoch 40/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5116, Avg Metric: 0.5454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:59<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 41/100, Train Loss: 52.4929, Train Accuracy: 0.1250\n",
      "Epoch 41/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5153, Avg Metric: 0.5466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:59<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 42/100, Train Loss: 52.4282, Train Accuracy: 0.1250\n",
      "Epoch 42/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5226, Avg Metric: 0.5491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:59<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 43/100, Train Loss: 52.1727, Train Accuracy: 0.1250\n",
      "Epoch 43/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5268, Avg Metric: 0.5505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:59<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 44/100, Train Loss: 53.2181, Train Accuracy: 0.1250\n",
      "Epoch 44/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5162, Avg Metric: 0.5469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:59<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 45/100, Train Loss: 52.3785, Train Accuracy: 0.1250\n",
      "Epoch 45/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5025, Avg Metric: 0.5424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:00<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 46/100, Train Loss: 52.1674, Train Accuracy: 0.1250\n",
      "Epoch 46/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5112, Avg Metric: 0.5453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:00<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 47/100, Train Loss: 52.2234, Train Accuracy: 0.1250\n",
      "Epoch 47/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5099, Avg Metric: 0.5448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [03:00<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 48/100, Train Loss: 52.5572, Train Accuracy: 0.1250\n",
      "Epoch 48/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5223, Avg Metric: 0.5490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:53<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 49/100, Train Loss: 51.9153, Train Accuracy: 0.1250\n",
      "Epoch 49/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5144, Avg Metric: 0.5463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:47<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 50/100, Train Loss: 52.7574, Train Accuracy: 0.1250\n",
      "Epoch 50/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5285, Avg Metric: 0.5510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 51/100, Train Loss: 51.7009, Train Accuracy: 0.1250\n",
      "Epoch 51/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5213, Avg Metric: 0.5486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 52/100, Train Loss: 52.1258, Train Accuracy: 0.1250\n",
      "Epoch 52/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5329, Avg Metric: 0.5525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 53/100, Train Loss: 51.8648, Train Accuracy: 0.1250\n",
      "Epoch 53/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5256, Avg Metric: 0.5501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 54/100, Train Loss: 51.5537, Train Accuracy: 0.1250\n",
      "Epoch 54/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5447, Avg Metric: 0.5564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 55/100, Train Loss: 52.0584, Train Accuracy: 0.1250\n",
      "Epoch 55/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5289, Avg Metric: 0.5512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 56/100, Train Loss: 51.7471, Train Accuracy: 0.1250\n",
      "Epoch 56/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5200, Avg Metric: 0.5482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 57/100, Train Loss: 51.1895, Train Accuracy: 0.1250\n",
      "Epoch 57/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5275, Avg Metric: 0.5507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:47<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 58/100, Train Loss: 51.9151, Train Accuracy: 0.1250\n",
      "Epoch 58/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5073, Avg Metric: 0.5440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:47<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 59/100, Train Loss: 51.7652, Train Accuracy: 0.1250\n",
      "Epoch 59/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5164, Avg Metric: 0.5470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:47<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 60/100, Train Loss: 51.0780, Train Accuracy: 0.1250\n",
      "Epoch 60/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5040, Avg Metric: 0.5429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:47<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 61/100, Train Loss: 50.5865, Train Accuracy: 0.1250\n",
      "Epoch 61/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.4976, Avg Metric: 0.5407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 62/100, Train Loss: 51.7090, Train Accuracy: 0.1250\n",
      "Epoch 62/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5213, Avg Metric: 0.5486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:47<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 63/100, Train Loss: 51.3345, Train Accuracy: 0.1250\n",
      "Epoch 63/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5078, Avg Metric: 0.5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:47<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 64/100, Train Loss: 50.2817, Train Accuracy: 0.1250\n",
      "Epoch 64/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5274, Avg Metric: 0.5507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:47<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 65/100, Train Loss: 50.6984, Train Accuracy: 0.1250\n",
      "Epoch 65/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.4937, Avg Metric: 0.5394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 66/100, Train Loss: 51.0875, Train Accuracy: 0.1250\n",
      "Epoch 66/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5555, Avg Metric: 0.5600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:47<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 67/100, Train Loss: 50.3486, Train Accuracy: 0.1250\n",
      "Epoch 67/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5109, Avg Metric: 0.5452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:47<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 68/100, Train Loss: 50.6909, Train Accuracy: 0.1250\n",
      "Epoch 68/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5470, Avg Metric: 0.5572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:47<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 69/100, Train Loss: 50.0499, Train Accuracy: 0.1250\n",
      "Epoch 69/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5333, Avg Metric: 0.5526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 70/100, Train Loss: 49.1321, Train Accuracy: 0.1250\n",
      "Epoch 70/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5600, Avg Metric: 0.5615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 71/100, Train Loss: 49.2206, Train Accuracy: 0.1250\n",
      "Epoch 71/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5197, Avg Metric: 0.5481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 72/100, Train Loss: 49.9079, Train Accuracy: 0.1250\n",
      "Epoch 72/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5180, Avg Metric: 0.5475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 73/100, Train Loss: 49.3599, Train Accuracy: 0.1250\n",
      "Epoch 73/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5621, Avg Metric: 0.5622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 74/100, Train Loss: 48.8096, Train Accuracy: 0.1250\n",
      "Epoch 74/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5307, Avg Metric: 0.5518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 75/100, Train Loss: 48.8552, Train Accuracy: 0.1250\n",
      "Epoch 75/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5622, Avg Metric: 0.5623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 76/100, Train Loss: 49.0523, Train Accuracy: 0.1250\n",
      "Epoch 76/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5389, Avg Metric: 0.5545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:47<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 77/100, Train Loss: 47.6694, Train Accuracy: 0.1250\n",
      "Epoch 77/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5174, Avg Metric: 0.5473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:47<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 78/100, Train Loss: 46.8906, Train Accuracy: 0.1250\n",
      "Epoch 78/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5325, Avg Metric: 0.5524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 79/100, Train Loss: 48.0183, Train Accuracy: 0.1250\n",
      "Epoch 79/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5215, Avg Metric: 0.5487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 80/100, Train Loss: 47.4470, Train Accuracy: 0.1250\n",
      "Epoch 80/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5537, Avg Metric: 0.5594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 81/100, Train Loss: 48.9543, Train Accuracy: 0.1250\n",
      "Epoch 81/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5157, Avg Metric: 0.5468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:47<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 82/100, Train Loss: 45.9247, Train Accuracy: 0.1250\n",
      "Epoch 82/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.4999, Avg Metric: 0.5415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 83/100, Train Loss: 45.8322, Train Accuracy: 0.1250\n",
      "Epoch 83/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5453, Avg Metric: 0.5566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 84/100, Train Loss: 47.0941, Train Accuracy: 0.1250\n",
      "Epoch 84/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5224, Avg Metric: 0.5490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 85/100, Train Loss: 44.7778, Train Accuracy: 0.1250\n",
      "Epoch 85/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5303, Avg Metric: 0.5516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 86/100, Train Loss: 46.2117, Train Accuracy: 0.1250\n",
      "Epoch 86/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5430, Avg Metric: 0.5559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 87/100, Train Loss: 43.9924, Train Accuracy: 0.1250\n",
      "Epoch 87/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5229, Avg Metric: 0.5492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:47<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 88/100, Train Loss: 46.3648, Train Accuracy: 0.1250\n",
      "Epoch 88/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5186, Avg Metric: 0.5477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:47<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 89/100, Train Loss: 43.7827, Train Accuracy: 0.1250\n",
      "Epoch 89/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5266, Avg Metric: 0.5504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:47<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 90/100, Train Loss: 42.7669, Train Accuracy: 0.1250\n",
      "Epoch 90/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5247, Avg Metric: 0.5498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 91/100, Train Loss: 44.0819, Train Accuracy: 0.1250\n",
      "Epoch 91/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5166, Avg Metric: 0.5471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 92/100, Train Loss: 43.5474, Train Accuracy: 0.1250\n",
      "Epoch 92/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5579, Avg Metric: 0.5609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [02:48<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0 548]\n",
      " [  0  78]]\n",
      "Epoch 93/100, Train Loss: 41.8880, Train Accuracy: 0.1250\n",
      "Epoch 93/100, Val Accuracy: 0.1246, Precision: 0.1246, Recall: 1.0000, AUC: 0.5259, Avg Metric: 0.5502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 27/59 [01:20<01:34,  2.97s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 17\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      3\u001b[0m     criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_models/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/iaaa-project/train.py:112\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs):\n\u001b[0;32m--> 112\u001b[0m         train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m         val_accuracy, precision, recall, auc, avg_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;250m              \u001b[39mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/iaaa-project/train.py:32\u001b[0m, in \u001b[0;36mTrainer.train_one_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     30\u001b[0m train_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 32\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/iaaa-project/iaaa-venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/Projects/iaaa-project/iaaa-venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Projects/iaaa-project/iaaa-venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Projects/iaaa-project/iaaa-venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Projects/iaaa-project/datasets.py:55\u001b[0m, in \u001b[0;36mMRIDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     52\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_patient_images(patient_id)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m---> 55\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     images \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor(img, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m images]\n",
      "File \u001b[0;32m~/Projects/iaaa-project/iaaa-venv/lib/python3.12/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/Projects/iaaa-project/iaaa-venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/iaaa-project/iaaa-venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/iaaa-project/iaaa-venv/lib/python3.12/site-packages/torchvision/transforms/transforms.py:1372\u001b[0m, in \u001b[0;36mRandomRotation.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         fill \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fill]\n\u001b[1;32m   1370\u001b[0m angle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegrees)\n\u001b[0;32m-> 1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/iaaa-project/iaaa-venv/lib/python3.12/site-packages/torchvision/transforms/functional.py:1123\u001b[0m, in \u001b[0;36mrotate\u001b[0;34m(img, angle, interpolation, expand, center, fill)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;66;03m# due to current incoherence of rotation angle direction between affine and rotate implementations\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;66;03m# we need to set -angle.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m matrix \u001b[38;5;241m=\u001b[39m _get_inverse_affine_matrix(center_f, \u001b[38;5;241m-\u001b[39mangle, [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m], \u001b[38;5;241m1.0\u001b[39m, [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m])\n\u001b[0;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/iaaa-project/iaaa-venv/lib/python3.12/site-packages/torchvision/transforms/_functional_tensor.py:667\u001b[0m, in \u001b[0;36mrotate\u001b[0;34m(img, matrix, interpolation, expand, fill)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;66;03m# grid will be generated on the same device as theta and img\u001b[39;00m\n\u001b[1;32m    665\u001b[0m grid \u001b[38;5;241m=\u001b[39m _gen_affine_grid(theta, w\u001b[38;5;241m=\u001b[39mw, h\u001b[38;5;241m=\u001b[39mh, ow\u001b[38;5;241m=\u001b[39mow, oh\u001b[38;5;241m=\u001b[39moh)\n\u001b[0;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_grid_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/iaaa-project/iaaa-venv/lib/python3.12/site-packages/torchvision/transforms/_functional_tensor.py:558\u001b[0m, in \u001b[0;36m_apply_grid_transform\u001b[0;34m(img, grid, mode, fill)\u001b[0m\n\u001b[1;32m    555\u001b[0m     mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m]), dtype\u001b[38;5;241m=\u001b[39mimg\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mimg\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    556\u001b[0m     img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((img, mask), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 558\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzeros\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;66;03m# Fill with required color\u001b[39;00m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fill \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Projects/iaaa-project/iaaa-venv/lib/python3.12/site-packages/torch/nn/functional.py:4351\u001b[0m, in \u001b[0;36mgrid_sample\u001b[0;34m(input, grid, mode, padding_mode, align_corners)\u001b[0m\n\u001b[1;32m   4343\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   4344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefault grid_sample and affine_grid behavior has changed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto align_corners=False since 1.3.0. Please specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4346\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malign_corners=True if the old behavior is desired. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4347\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee the documentation of grid_sample for details.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4348\u001b[0m     )\n\u001b[1;32m   4349\u001b[0m     align_corners \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 4351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid_sampler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_enum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mode_enum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    train_dl=train_dl,\n",
    "    val_dl=val_dl,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    device=device,\n",
    "    num_epochs=100,\n",
    "    patience=50,\n",
    "    threshold=0,\n",
    "    save_path=f\"saved_models/{model_name}.pth\"\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fateme/Projects/iaaa-project/iaaa-venv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/fateme/Projects/iaaa-project/iaaa-venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MriResentModel(20,1).to(device)\n",
    "model.load_state_dict(torch.load(f\"saved_models/{model_name}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7604, Precision: 0.2049, Recall: 0.3205, AUC: 0.5926, Avg Metric: 0.3727\n"
     ]
    }
   ],
   "source": [
    "tester = Tester(\n",
    "    model=model,\n",
    "    test_dl=test_dl,\n",
    "    test_dataset=test_dataset,\n",
    "    device=device,\n",
    "    threshold=0  # Set the threshold for binary classification\n",
    ")\n",
    "\n",
    "# Perform testing and print metrics\n",
    "tester.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
