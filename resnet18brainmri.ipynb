{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model : BehradG/resnet-18-finetuned-MRI-Brain\n",
    "resnet18 pretrained on brain mri images\n",
    "model first layer modified to take 1-channel image instead of 3-channel\n",
    "model last layer modified to output=1 instead of output=2\n",
    "model fine tuned on just first layer and last layer \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.utils.class_weight import compute_class_weight       \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from config import Config, Device\n",
    "from datasets import MRIDataset, BalancedMRIDataset\n",
    "from models import ResNet18MRI\n",
    "from train import Trainer_for_resnet18\n",
    "from test_file import Tester    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = Device.device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(), \"data\")\n",
    "labels_path = \"train.csv\"\n",
    "\n",
    "batch_size = Config.batch_size\n",
    "num_epochs = Config.num_epochs\n",
    "learning_rate = Config.learning_rate\n",
    "mean = Config.mean # mean of the entire datasaet\n",
    "std = Config.std # std of the entire dataaset\n",
    "image_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resclaed_mean = round(mean/255,4) # re-scale the actual mean\n",
    "rescaled_std = round(std/255, 4) # re-scale the actual std\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[resclaed_mean], std=[rescaled_std])\n",
    "])\n",
    "\n",
    "augment_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    # transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[resclaed_mean], std=[rescaled_std])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    # transforms.Lambda(lambda img: img.astype(np.float32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize(mean=[resclaed_mean], std=[rescaled_std])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = BalancedMRIDataset(\n",
    "    data_path,\n",
    "    labels_path,\n",
    "    split='train',\n",
    "    transform=train_transforms,\n",
    "    augment_transform=augment_transforms,\n",
    "    augment=True,\n",
    "    max_slices=20\n",
    ")\n",
    "\n",
    "val_dataset = BalancedMRIDataset(\n",
    "    data_path,\n",
    "    labels_path,\n",
    "    split='val',\n",
    "    transform=test_transforms,\n",
    "    max_slices=20\n",
    ")\n",
    "\n",
    "test_dataset = BalancedMRIDataset(\n",
    "    data_path,\n",
    "    labels_path,\n",
    "    split='test',\n",
    "    transform=test_transforms,\n",
    "    max_slices=20\n",
    ")\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size=32)\n",
    "test_dl = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20, 224, 224])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_, label_ = next(iter(train_dl))\n",
    "data_.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at BehradG/resnet-18-finetuned-MRI-Brain and are newly initialized because the shapes did not match:\n",
      "- resnet.embedder.embedder.convolution.weight: found shape torch.Size([64, 3, 7, 7]) in the checkpoint and torch.Size([64, 1, 7, 7]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18MRI().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "# criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ResNet18MRI'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = model.__class__.__name__\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [13:39<00:00,  9.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[10820   140]\n",
      " [ 1560     0]]\n",
      "Epoch 1/10, Train Loss: 890.7513, Train Accuracy: 0.7603\n",
      "Epoch 1/10, Val Accuracy: 17.2843, Precision: 0.0000, Recall: 0.0000, AUC: 0.4936, Avg Metric: 5.7614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [09:17<00:00,  6.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[10880    80]\n",
      " [ 1520    40]]\n",
      "Epoch 2/10, Train Loss: 840.2845, Train Accuracy: 0.7833\n",
      "Epoch 2/10, Val Accuracy: 17.4441, Precision: 0.3333, Recall: 0.0256, AUC: 0.5092, Avg Metric: 5.9344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [08:35<00:00,  5.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[10860   100]\n",
      " [ 1540    20]]\n",
      "Epoch 3/10, Train Loss: 833.3933, Train Accuracy: 0.7869\n",
      "Epoch 3/10, Val Accuracy: 17.3802, Precision: 0.1667, Recall: 0.0128, AUC: 0.5018, Avg Metric: 5.8532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [08:35<00:00,  5.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[10880    80]\n",
      " [ 1540    20]]\n",
      "Epoch 4/10, Train Loss: 838.6473, Train Accuracy: 0.7734\n",
      "Epoch 4/10, Val Accuracy: 17.4121, Precision: 0.2000, Recall: 0.0128, AUC: 0.5028, Avg Metric: 5.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [08:42<00:00,  5.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[10520   440]\n",
      " [ 1520    40]]\n",
      "Epoch 5/10, Train Loss: 836.0139, Train Accuracy: 0.7833\n",
      "Epoch 5/10, Val Accuracy: 16.8690, Precision: 0.0833, Recall: 0.0256, AUC: 0.4927, Avg Metric: 5.6593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [08:35<00:00,  5.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[10960     0]\n",
      " [ 1560     0]]\n",
      "Epoch 6/10, Train Loss: 836.3028, Train Accuracy: 0.7706\n",
      "Epoch 6/10, Val Accuracy: 17.5080, Precision: 0.0000, Recall: 0.0000, AUC: 0.5000, Avg Metric: 5.8360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [08:37<00:00,  5.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[10880    80]\n",
      " [ 1560     0]]\n",
      "Epoch 7/10, Train Loss: 833.8117, Train Accuracy: 0.7794\n",
      "Epoch 7/10, Val Accuracy: 17.3802, Precision: 0.0000, Recall: 0.0000, AUC: 0.4964, Avg Metric: 5.7934\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer_for_resnet18(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    train_dl=train_dl,\n",
    "    val_dl=val_dl,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    device=device,\n",
    "    num_epochs=10,\n",
    "    patience=5,\n",
    "    threshold=0.5,\n",
    "    save_path=f\"saved_models/{model_name}.pth\"\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
